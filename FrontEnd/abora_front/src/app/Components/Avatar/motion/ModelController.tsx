import { useGLTF, useAnimations } from '@react-three/drei';
import { useRef, useEffect, useState } from 'react';
import { useFrame } from '@react-three/fiber';
import * as THREE from 'three';
import * as Hangul from 'hangul-js';
import mapKoreanToShape from '../../../utils/mapKoreanToShape';

type Props = {
    ModelComponent: React.ForwardRefExoticComponent<any>;
    glbPath: string;
    currentAction?: string;
    jsonFilename?: string;
    mp3Filename?: string;
    onAudioEnd?: () => void;
};

type TimelineItem = {
    phoneme: string;
    start: number;
    end: number;
};

export default function ModelController({
                                            ModelComponent,
                                            glbPath,
                                            currentAction = 'breath',
                                            jsonFilename,
                                            mp3Filename,
                                            onAudioEnd
                                        }: Props) {
    const modelRef = useRef<THREE.Object3D>(null);
    const meshRef = useRef<THREE.Mesh | null>(null);

    const { animations } = useGLTF(glbPath);
    const { actions } = useAnimations(animations, modelRef);

    const [currentPhoneme, setCurrentPhoneme] = useState<'AA' | 'II' | 'UU' | 'EE' | 'OO' | 'Idle'>('Idle');
    const [targetInfluences, setTargetInfluences] = useState<number[]>(Array(7).fill(0)); // 0~6

    const phonemeToIndex: Record<typeof currentPhoneme, number> = {
        Idle: 1,
        AA: 2,
        II: 3,
        UU: 4,
        EE: 5,
        OO: 6,
    };

    // âœ… ë¦½ì‹±í¬ + ìŒì„± ë™ê¸°í™”
    useEffect(() => {
        if (!jsonFilename || !mp3Filename) return;

        const playWithLipSync = async () => {
            const res = await fetch(`http://localhost:8000/tts/json/${jsonFilename}`);
            const segments: { text: string; start: number; end: number }[] = await res.json();

            if (!Array.isArray(segments)) {
                console.error('Invalid JSON structure:', segments);
                return;
            }

            const timeline: TimelineItem[] = [];

            for (const { text, start, end } of segments) {
                const jamos = Hangul.disassemble(text).filter((j: string) => j.trim());
                const duration = end - start;
                const per = duration / jamos.length;

                if (jamos.length === 0) {
                    timeline.push({ phoneme: 'II', start, end });
                } else {
                    jamos.forEach((j: string, i: number) => {
                        const phoneme = mapKoreanToShape(j);
                        timeline.push({
                            phoneme,
                            start: +(start + i * per).toFixed(2),
                            end: +(start + (i + 1) * per).toFixed(2),
                        });
                    });
                }
            }

            const audio = new Audio(`http://localhost:8000/tts/${mp3Filename}`);

            audio.onplay = () => {
                timeline.forEach(({ phoneme, start, end }) => {
                    setTimeout(() => setCurrentPhoneme(phoneme), start * 1000);
                    setTimeout(() => setCurrentPhoneme('Idle'), end * 1000);
                });
            };

            await new Promise<void>((resolve) => {
                audio.onended = () => {
                    onAudioEnd?.(); // ì™¸ë¶€ë¡œ ì¬ìƒ ë ì•Œë¦¼
                    resolve();
                };
                audio.play();
            });


        };

        playWithLipSync();
    }, [jsonFilename, mp3Filename]);

    // ì…ëª¨ì–‘ ì‰ì´í”„í‚¤ ë³€ê²½
    useEffect(() => {
        const newTargets = Array(7).fill(0);
        const index = phonemeToIndex[currentPhoneme];

        if (currentPhoneme === 'Idle') {
            newTargets[1] = 1;
        } else if (index !== undefined && index !== null) {
            newTargets[index] = 1;
        }

        setTargetInfluences(newTargets);
    }, [currentPhoneme]);

    // ë¶€ë“œëŸ½ê²Œ ì‰ì´í”„í‚¤ ì ìš©
    useFrame(() => {
        if (!meshRef.current || !meshRef.current.morphTargetInfluences) return;
        const influences = meshRef.current.morphTargetInfluences;
        for (let i = 0; i < targetInfluences.length; i++) {
            influences[i] += (targetInfluences[i] - influences[i]) * 0.2;
        }
    });

    // ğŸ¤– ì…ëª¨ì–‘ íƒ€ê²Ÿ ë©”ì‰¬ ì°¾ì•„ì˜¤ê¸°
    useEffect(() => {
        if (!modelRef.current) return;
        modelRef.current.traverse((child: any) => {
            if (child.isMesh && child.morphTargetInfluences && child.name.toLowerCase().includes('mouse')) {
                meshRef.current = child;
            }
        });
    }, []);

    // ì• ë‹ˆë©”ì´ì…˜ ì „í™˜
    useEffect(() => {
        if (!actions || !currentAction) return;

        const mappedAction =
            currentAction === 'Reading' ? 'left_Reading' :
                currentAction === 'Idle' ? 'breath' :
                    currentAction;

        Object.values(actions).forEach((action) => {
            if (action) action.fadeOut(0.2);
        });

        const actionToPlay = actions[mappedAction];
        if (actionToPlay) {

            if (mappedAction === 'left_pending' || mappedAction === 'right_pending') {
                actionToPlay.timeScale = 0.5; // ì›ë˜ ì†ë„ì˜ 60%
            } else {
                actionToPlay.timeScale = 1.0; // ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ ì†ë„
            }


            actionToPlay.reset().fadeIn(0.3).play();
        } else {
            console.warn(" ì• ë‹ˆë©”ì´ì…˜ ì—†ìŒ:", mappedAction);
        }
    }, [actions, currentAction]);

    return <ModelComponent ref={modelRef} />;
}
